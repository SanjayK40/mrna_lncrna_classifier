{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"def plot_cnn(model,X_val,y_val):\n    print('-'*60)\n    print('cnn')\n    y_val_pred = model.predict(X_val)\n    threshold = 0.5  \n    y_val_pred = (y_val_pred > threshold).astype(int)\n    \n    accuracy = accuracy_score(y_val, y_val_pred)\n    print(f'Accuracy: {accuracy:.2f}')\n\n    precision = precision_score(y_val, y_val_pred, average='micro')\n    print(f'Precision: {precision:.2f}')\n\n    recall = recall_score(y_val, y_val_pred, average='micro')\n    print(f'Recall: {recall:.2f}')\n\n    f1 = f1_score(y_val, y_val_pred, average='micro')\n    print(f'F1 Score: {f1:.2f}')\n\n    confusion_mat = multilabel_confusion_matrix(y_val, y_val_pred)\n    print(f'Confusion Matrix:\\n{confusion_mat}')\n\n    fpr, tpr, _ = roc_curve(label_binarize(y_val, classes=[0, 1]).ravel(), y_val_pred.ravel())\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(12, 6))\n\n    # Plot ROC curve\n    lw = 2\n    plt.subplot(1, 2, 1)\n    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = {:.2f})'.format(roc_auc))\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc='lower right')\n\n    # Plot Confusion Matrix for each class\n    num_classes = confusion_mat.shape[0]\n    for i in range(num_classes):\n        plt.subplot(1, 2, 2)\n        plt.imshow(confusion_mat[i], interpolation='nearest', cmap=plt.cm.Blues)\n        plt.title(f'Confusion Matrix - Class {i}')\n        plt.colorbar()\n        plt.xlabel('Predicted Label')\n        plt.ylabel('True Label')\n        plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_ml(model,X_val,y_val,name):\n    print('-'*60)\n    print(name)\n    y_val_pred = model.predict(X_val)\n    accuracy = accuracy_score(y_val, y_val_pred)\n    print(f'Accuracy: {accuracy:.2f}')\n\n    precision = precision_score(y_val, y_val_pred, average='micro')\n    print(f'Precision: {precision:.2f}')\n\n    recall = recall_score(y_val, y_val_pred, average='micro')\n    print(f'Recall: {recall:.2f}')\n\n    f1 = f1_score(y_val, y_val_pred, average='micro')\n    print(f'F1 Score: {f1:.2f}')\n\n    confusion_mat = multilabel_confusion_matrix(y_val, y_val_pred)\n    print(f'Confusion Matrix:\\n{confusion_mat}')\n\n    fpr, tpr, _ = roc_curve(label_binarize(y_val, classes=[0, 1]).ravel(), y_val_pred.ravel())\n    roc_auc = auc(fpr, tpr)\n    \n    plt.figure(figsize=(12, 6))\n\n    # Plot ROC curve\n    lw = 2\n    plt.subplot(1, 2, 1)\n    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = {:.2f})'.format(roc_auc))\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc='lower right')\n    \n    # Plot Confusion Matrix for each class\n    num_classes = confusion_mat.shape[0]\n    for i in range(num_classes):\n        plt.subplot(1, 2, 2)\n        plt.imshow(confusion_mat[i], interpolation='nearest', cmap=plt.cm.Blues)\n        plt.title(f'Confusion Matrix - Class {i}')\n        plt.colorbar()\n        plt.xlabel('Predicted Label')\n        plt.ylabel('True Label')\n        plt.show()\n    print('\\n')","metadata":{},"execution_count":null,"outputs":[]}]}